{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizing Models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# sklearn \n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, \\\n",
    "    precision_recall_curve, roc_curve, roc_auc_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, ExtraTreesClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>avi_danger</th>\n",
       "      <th>avg_wind</th>\n",
       "      <th>temp_max_swing</th>\n",
       "      <th>temp_max_swing_from_avg</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>temp_max</th>\n",
       "      <th>temp_min</th>\n",
       "      <th>...</th>\n",
       "      <th>prevailing_wind_N_2</th>\n",
       "      <th>prevailing_wind_NE_2</th>\n",
       "      <th>prevailing_wind_NW_2</th>\n",
       "      <th>prevailing_wind_S_2</th>\n",
       "      <th>prevailing_wind_SE_2</th>\n",
       "      <th>prevailing_wind_SW_2</th>\n",
       "      <th>prevailing_wind_W_2</th>\n",
       "      <th>three_day_snow_2</th>\n",
       "      <th>five_day_snow_2</th>\n",
       "      <th>next_day_avi_danger</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.58</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>35.12</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>18</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>33.78</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>15</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>31.32</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.3</td>\n",
       "      <td>4.5</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>32.44</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>17</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.3</td>\n",
       "      <td>8.6</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 74 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  avi_danger  avg_wind  temp_max_swing  temp_max_swing_from_avg  \\\n",
       "0           0         1.0     20.58             0.0                      0.0   \n",
       "1           1         3.0     35.12             3.0                      0.0   \n",
       "2           2         2.0     33.78            -3.0                      0.0   \n",
       "3           3         3.0     31.32             0.0                      0.0   \n",
       "4           4         2.0     32.44             2.0                      1.4   \n",
       "\n",
       "     year  month   day  temp_max  temp_min  ...  prevailing_wind_N_2  \\\n",
       "0  2010.0   12.0  20.0        15         5  ...                  0.0   \n",
       "1  2010.0   12.0  21.0        18        10  ...                  0.0   \n",
       "2  2010.0   12.0  22.0        15         7  ...                  1.0   \n",
       "3  2010.0   12.0  23.0        15         6  ...                  1.0   \n",
       "4  2010.0   12.0  24.0        17         9  ...                  1.0   \n",
       "\n",
       "   prevailing_wind_NE_2  prevailing_wind_NW_2  prevailing_wind_S_2  \\\n",
       "0                   0.0                   1.0                  0.0   \n",
       "1                   0.0                   1.0                  0.0   \n",
       "2                   0.0                   0.0                  0.0   \n",
       "3                   0.0                   0.0                  0.0   \n",
       "4                   0.0                   0.0                  0.0   \n",
       "\n",
       "   prevailing_wind_SE_2  prevailing_wind_SW_2  prevailing_wind_W_2  \\\n",
       "0                   0.0                   0.0                  0.0   \n",
       "1                   0.0                   0.0                  0.0   \n",
       "2                   0.0                   0.0                  0.0   \n",
       "3                   0.0                   0.0                  0.0   \n",
       "4                   0.0                   0.0                  0.0   \n",
       "\n",
       "   three_day_snow_2  five_day_snow_2  next_day_avi_danger  \n",
       "0               0.2              0.2                  3.0  \n",
       "1               0.3              0.3                  2.0  \n",
       "2               2.5              2.5                  3.0  \n",
       "3               4.3              4.5                  2.0  \n",
       "4               8.3              8.6                  2.0  \n",
       "\n",
       "[5 rows x 74 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avi = pd.read_csv('SnowWeatherCleanROS.csv')\n",
    "avi.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1876 entries, 0 to 1875\n",
      "Data columns (total 74 columns):\n",
      " #   Column                     Non-Null Count  Dtype  \n",
      "---  ------                     --------------  -----  \n",
      " 0   Unnamed: 0                 1876 non-null   int64  \n",
      " 1   avi_danger                 1876 non-null   float64\n",
      " 2   avg_wind                   1876 non-null   float64\n",
      " 3   temp_max_swing             1876 non-null   float64\n",
      " 4   temp_max_swing_from_avg    1876 non-null   float64\n",
      " 5   year                       1876 non-null   float64\n",
      " 6   month                      1876 non-null   float64\n",
      " 7   day                        1876 non-null   float64\n",
      " 8   temp_max                   1876 non-null   int64  \n",
      " 9   temp_min                   1876 non-null   int64  \n",
      " 10  water_equivalent           1876 non-null   float64\n",
      " 11  snow_fall                  1876 non-null   float64\n",
      " 12  snow_depth_6am             1876 non-null   float64\n",
      " 13  wind_speed_sum             1876 non-null   int64  \n",
      " 14  sunshine_percent           1876 non-null   int64  \n",
      " 15  west_wind_hours            1876 non-null   int64  \n",
      " 16  northwest_wind_hours       1876 non-null   int64  \n",
      " 17  prevailing_wind_E          1876 non-null   int64  \n",
      " 18  prevailing_wind_N          1876 non-null   int64  \n",
      " 19  prevailing_wind_NE         1876 non-null   int64  \n",
      " 20  prevailing_wind_NW         1876 non-null   int64  \n",
      " 21  prevailing_wind_S          1876 non-null   int64  \n",
      " 22  prevailing_wind_SE         1876 non-null   int64  \n",
      " 23  prevailing_wind_SW         1876 non-null   int64  \n",
      " 24  prevailing_wind_W          1876 non-null   int64  \n",
      " 25  three_day_snow             1876 non-null   float64\n",
      " 26  five_day_snow              1876 non-null   float64\n",
      " 27  avi_danger_1               1876 non-null   float64\n",
      " 28  avg_wind_1                 1876 non-null   float64\n",
      " 29  temp_max_swing_1           1876 non-null   float64\n",
      " 30  temp_max_swing_from_avg_1  1876 non-null   float64\n",
      " 31  temp_max_1                 1876 non-null   float64\n",
      " 32  temp_min_1                 1876 non-null   float64\n",
      " 33  water_equivalent_1         1876 non-null   float64\n",
      " 34  snow_fall_1                1876 non-null   float64\n",
      " 35  snow_depth_6am_1           1876 non-null   float64\n",
      " 36  wind_speed_sum_1           1876 non-null   float64\n",
      " 37  sunshine_percent_1         1876 non-null   float64\n",
      " 38  west_wind_hours_1          1876 non-null   float64\n",
      " 39  northwest_wind_hours_1     1876 non-null   float64\n",
      " 40  prevailing_wind_E_1        1876 non-null   float64\n",
      " 41  prevailing_wind_N_1        1876 non-null   float64\n",
      " 42  prevailing_wind_NE_1       1876 non-null   float64\n",
      " 43  prevailing_wind_NW_1       1876 non-null   float64\n",
      " 44  prevailing_wind_S_1        1876 non-null   float64\n",
      " 45  prevailing_wind_SE_1       1876 non-null   float64\n",
      " 46  prevailing_wind_SW_1       1876 non-null   float64\n",
      " 47  prevailing_wind_W_1        1876 non-null   float64\n",
      " 48  three_day_snow_1           1876 non-null   float64\n",
      " 49  five_day_snow_1            1876 non-null   float64\n",
      " 50  avi_danger_2               1876 non-null   float64\n",
      " 51  avg_wind_2                 1876 non-null   float64\n",
      " 52  temp_max_swing_2           1876 non-null   float64\n",
      " 53  temp_max_swing_from_avg_2  1876 non-null   float64\n",
      " 54  temp_max_2                 1876 non-null   float64\n",
      " 55  temp_min_2                 1876 non-null   float64\n",
      " 56  water_equivalent_2         1876 non-null   float64\n",
      " 57  snow_fall_2                1876 non-null   float64\n",
      " 58  snow_depth_6am_2           1876 non-null   float64\n",
      " 59  wind_speed_sum_2           1876 non-null   float64\n",
      " 60  sunshine_percent_2         1876 non-null   float64\n",
      " 61  west_wind_hours_2          1876 non-null   float64\n",
      " 62  northwest_wind_hours_2     1876 non-null   float64\n",
      " 63  prevailing_wind_E_2        1876 non-null   float64\n",
      " 64  prevailing_wind_N_2        1876 non-null   float64\n",
      " 65  prevailing_wind_NE_2       1876 non-null   float64\n",
      " 66  prevailing_wind_NW_2       1876 non-null   float64\n",
      " 67  prevailing_wind_S_2        1876 non-null   float64\n",
      " 68  prevailing_wind_SE_2       1876 non-null   float64\n",
      " 69  prevailing_wind_SW_2       1876 non-null   float64\n",
      " 70  prevailing_wind_W_2        1876 non-null   float64\n",
      " 71  three_day_snow_2           1876 non-null   float64\n",
      " 72  five_day_snow_2            1876 non-null   float64\n",
      " 73  next_day_avi_danger        1876 non-null   float64\n",
      "dtypes: float64(59), int64(15)\n",
      "memory usage: 1.1 MB\n"
     ]
    }
   ],
   "source": [
    "avi.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### filter data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "avi = avi.drop(['Unnamed: 0'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# avi = avi.drop(['prevailing_wind_E', 'prevailing_wind_N', 'prevailing_wind_NE', 'prevailing_wind_NW',\n",
    "#                 'prevailing_wind_S', 'prevailing_wind_SE', 'prevailing_wind_SW', 'prevailing_wind_W',\n",
    "#                 'prevailing_wind_E_1', 'prevailing_wind_N_1', 'prevailing_wind_NE_1', 'prevailing_wind_NW_1',\n",
    "#                 'prevailing_wind_S_1', 'prevailing_wind_SE_1', 'prevailing_wind_SW_1', 'prevailing_wind_W_1',\n",
    "#                 'prevailing_wind_E_2', 'prevailing_wind_N_2', 'prevailing_wind_NE_2', 'prevailing_wind_NW_2',\n",
    "#                 'prevailing_wind_S_2', 'prevailing_wind_SE_2', 'prevailing_wind_SW_2', 'prevailing_wind_W_2'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Splitting Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1876, 72)\n",
      "(1876,)\n"
     ]
    }
   ],
   "source": [
    "x = avi.iloc[:, 0:avi.shape[1]-1]\n",
    "y = avi.iloc[:, avi.shape[1]-1]\n",
    "\n",
    "print(x.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Standardizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#standardizer \n",
    "def standardize(X_train, X_test):\n",
    "    scaler = StandardScaler()\n",
    "    # Fitting and transforming training data\n",
    "    scaler.fit(X_train)\n",
    "    X_train = scaler.transform(X_train)\n",
    "    # Tranforming testing data based on traning fit (prevent data leakage)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    return X_train, X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=42)\n",
    "\n",
    "# Scaling\n",
    "x_train, x_test = standardize(x_train, x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       3.0\n",
      "1       2.0\n",
      "2       3.0\n",
      "3       2.0\n",
      "4       2.0\n",
      "       ... \n",
      "1871    4.0\n",
      "1872    4.0\n",
      "1873    4.0\n",
      "1874    4.0\n",
      "1875    4.0\n",
      "Name: next_day_avi_danger, Length: 1876, dtype: float64\n",
      "[[  1. 469.]\n",
      " [  2. 469.]\n",
      " [  3. 469.]\n",
      " [  4. 469.]]\n"
     ]
    }
   ],
   "source": [
    "print(y)\n",
    "\n",
    "(unique, counts) = np.unique(y, return_counts=True)\n",
    "frequencies = np.asarray((unique, counts)).T\n",
    "\n",
    "print(frequencies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8187633262260128\n",
      "[0.75906183 0.74200426 0.76759062]\n"
     ]
    }
   ],
   "source": [
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "\n",
    "\n",
    "rf = RandomForestClassifier(class_weight = \"balanced\")\n",
    "rf_cv = RandomizedSearchCV(estimator=rf, param_distributions=random_grid, n_iter=5, scoring='f1_weighted')\n",
    "rf_cv.fit(x_train, y_train)\n",
    "y_pred_rf = rf_cv.predict(x_test)\n",
    "print(accuracy_score(y_test, y_pred_rf))\n",
    "print(cross_val_score(rf, x_train, y_train, cv=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 200, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 'auto', 'max_depth': 100, 'bootstrap': False}\n"
     ]
    }
   ],
   "source": [
    "print(rf_cv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 92  15   4   0]\n",
      " [ 17  86  17   1]\n",
      " [  7  22  88   2]\n",
      " [  0   0   0 118]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, y_pred_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.79      0.83      0.81       111\n",
      "         2.0       0.70      0.71      0.70       121\n",
      "         3.0       0.81      0.74      0.77       119\n",
      "         4.0       0.98      1.00      0.99       118\n",
      "\n",
      "    accuracy                           0.82       469\n",
      "   macro avg       0.82      0.82      0.82       469\n",
      "weighted avg       0.82      0.82      0.82       469\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred_rf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8123667377398721\n",
      "[0.76545842 0.77185501 0.7761194 ]\n"
     ]
    }
   ],
   "source": [
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "\n",
    "et = ExtraTreesClassifier(class_weight = \"balanced\")\n",
    "et_cv = RandomizedSearchCV(estimator=et, param_distributions=random_grid, n_iter=5, scoring='f1_weighted')\n",
    "et_cv.fit(x_train, y_train)\n",
    "y_pred_et = et_cv.predict(x_test)\n",
    "print(accuracy_score(y_test, y_pred_et))\n",
    "print(cross_val_score(rf, x_train, y_train, cv=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 1800, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'max_depth': 80, 'bootstrap': True}\n"
     ]
    }
   ],
   "source": [
    "print(et_cv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 95  12   4   0]\n",
      " [ 22  78  21   0]\n",
      " [  7  20  90   2]\n",
      " [  0   0   0 118]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, y_pred_et))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.77      0.86      0.81       111\n",
      "         2.0       0.71      0.64      0.68       121\n",
      "         3.0       0.78      0.76      0.77       119\n",
      "         4.0       0.98      1.00      0.99       118\n",
      "\n",
      "    accuracy                           0.81       469\n",
      "   macro avg       0.81      0.81      0.81       469\n",
      "weighted avg       0.81      0.81      0.81       469\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred_et))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8187633262260128\n",
      "[0.76759062 0.73773987 0.73987207]\n"
     ]
    }
   ],
   "source": [
    "param_distributions = {'learning_rate':[0.15,0.1,0.05,0.01,0.005,0.001], \n",
    "                       'n_estimators':[100,250,500,750,1000,1250,1500,1750],\n",
    "                       'max_depth':[2,3,4,5,6,7] }\n",
    "\n",
    "gbc = GradientBoostingClassifier(n_estimators=500, max_depth=4, learning_rate=0.05)\n",
    "# gbc_cv = RandomizedSearchCV(estimator=gbc, param_distributions= param_distributions, n_iter=5, scoring='f1_weighted')\n",
    "gbc.fit(x_train, y_train)\n",
    "y_pred_gbc = gbc.predict(x_test)\n",
    "print(accuracy_score(y_test, y_pred_gbc))\n",
    "print(cross_val_score(gbc, x_train, y_train, cv=3))\n",
    "\n",
    "# print(gbc_cv.best_params_)\n",
    "# {'n_estimators': 500, 'max_depth': 4, 'learning_rate': 0.05}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 90  14   6   1]\n",
      " [ 18  84  18   1]\n",
      " [  6  15  92   6]\n",
      " [  0   0   0 118]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, y_pred_gbc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.79      0.81      0.80       111\n",
      "         2.0       0.74      0.69      0.72       121\n",
      "         3.0       0.79      0.77      0.78       119\n",
      "         4.0       0.94      1.00      0.97       118\n",
      "\n",
      "    accuracy                           0.82       469\n",
      "   macro avg       0.82      0.82      0.82       469\n",
      "weighted avg       0.82      0.82      0.82       469\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred_gbc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
