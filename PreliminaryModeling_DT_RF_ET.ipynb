{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Danger Level Forecasting Preliminary Models\n",
    "\n",
    "Testing out some of the classification models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# sklearn \n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, ExtraTreesClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>avi_danger</th>\n",
       "      <th>avg_wind</th>\n",
       "      <th>temp_max_swing</th>\n",
       "      <th>temp_max_swing_from_avg</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>temp_max</th>\n",
       "      <th>temp_min</th>\n",
       "      <th>...</th>\n",
       "      <th>northwest_wind_hours</th>\n",
       "      <th>prevailing_wind_E</th>\n",
       "      <th>prevailing_wind_N</th>\n",
       "      <th>prevailing_wind_NE</th>\n",
       "      <th>prevailing_wind_NW</th>\n",
       "      <th>prevailing_wind_S</th>\n",
       "      <th>prevailing_wind_SE</th>\n",
       "      <th>prevailing_wind_SW</th>\n",
       "      <th>prevailing_wind_W</th>\n",
       "      <th>next_day_avi_danger</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.74</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.40</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.58</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>35.12</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>18</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>33.78</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>15</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  avi_danger  avg_wind  temp_max_swing  temp_max_swing_from_avg  \\\n",
       "0           0         2.0     10.74             0.0                      0.0   \n",
       "1           1         1.0      9.40             3.0                      0.0   \n",
       "2           2         1.0     20.58             0.0                      0.0   \n",
       "3           3         3.0     35.12             3.0                      0.0   \n",
       "4           4         2.0     33.78            -3.0                      0.0   \n",
       "\n",
       "     year  month   day  temp_max  temp_min  ...  northwest_wind_hours  \\\n",
       "0  2010.0   12.0  18.0        12         4  ...                    12   \n",
       "1  2010.0   12.0  19.0        15         3  ...                    12   \n",
       "2  2010.0   12.0  20.0        15         5  ...                     0   \n",
       "3  2010.0   12.0  21.0        18        10  ...                     0   \n",
       "4  2010.0   12.0  22.0        15         7  ...                     1   \n",
       "\n",
       "   prevailing_wind_E  prevailing_wind_N  prevailing_wind_NE  \\\n",
       "0                  0                  0                   0   \n",
       "1                  0                  0                   0   \n",
       "2                  0                  1                   0   \n",
       "3                  0                  1                   0   \n",
       "4                  0                  1                   0   \n",
       "\n",
       "   prevailing_wind_NW  prevailing_wind_S  prevailing_wind_SE  \\\n",
       "0                   1                  0                   0   \n",
       "1                   1                  0                   0   \n",
       "2                   0                  0                   0   \n",
       "3                   0                  0                   0   \n",
       "4                   0                  0                   0   \n",
       "\n",
       "   prevailing_wind_SW  prevailing_wind_W  next_day_avi_danger  \n",
       "0                   0                  0                  1.0  \n",
       "1                   0                  0                  1.0  \n",
       "2                   0                  0                  3.0  \n",
       "3                   0                  0                  2.0  \n",
       "4                   0                  0                  3.0  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avi = pd.read_csv('SnowWeatherClean.csv')\n",
    "avi.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### filter data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "avi = avi.drop(['Unnamed: 0'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1253 entries, 0 to 1252\n",
      "Data columns (total 25 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   avi_danger               1253 non-null   float64\n",
      " 1   avg_wind                 1253 non-null   float64\n",
      " 2   temp_max_swing           1253 non-null   float64\n",
      " 3   temp_max_swing_from_avg  1253 non-null   float64\n",
      " 4   year                     1253 non-null   float64\n",
      " 5   month                    1253 non-null   float64\n",
      " 6   day                      1253 non-null   float64\n",
      " 7   temp_max                 1253 non-null   int64  \n",
      " 8   temp_min                 1253 non-null   int64  \n",
      " 9   water_equivalent         1253 non-null   float64\n",
      " 10  snow_fall                1253 non-null   float64\n",
      " 11  snow_depth_6am           1253 non-null   float64\n",
      " 12  wind_speed_sum           1253 non-null   int64  \n",
      " 13  sunshine_percent         1253 non-null   int64  \n",
      " 14  west_wind_hours          1253 non-null   int64  \n",
      " 15  northwest_wind_hours     1253 non-null   int64  \n",
      " 16  prevailing_wind_E        1253 non-null   int64  \n",
      " 17  prevailing_wind_N        1253 non-null   int64  \n",
      " 18  prevailing_wind_NE       1253 non-null   int64  \n",
      " 19  prevailing_wind_NW       1253 non-null   int64  \n",
      " 20  prevailing_wind_S        1253 non-null   int64  \n",
      " 21  prevailing_wind_SE       1253 non-null   int64  \n",
      " 22  prevailing_wind_SW       1253 non-null   int64  \n",
      " 23  prevailing_wind_W        1253 non-null   int64  \n",
      " 24  next_day_avi_danger      1253 non-null   float64\n",
      "dtypes: float64(11), int64(14)\n",
      "memory usage: 254.5 KB\n"
     ]
    }
   ],
   "source": [
    "avi = avi[avi['avi_danger'].notnull()]\n",
    "avi.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fill Remaing NA's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1251 entries, 0 to 1252\n",
      "Data columns (total 25 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   avi_danger               1251 non-null   float64\n",
      " 1   avg_wind                 1251 non-null   float64\n",
      " 2   temp_max_swing           1251 non-null   float64\n",
      " 3   temp_max_swing_from_avg  1251 non-null   float64\n",
      " 4   year                     1251 non-null   float64\n",
      " 5   month                    1251 non-null   float64\n",
      " 6   day                      1251 non-null   float64\n",
      " 7   temp_max                 1251 non-null   int64  \n",
      " 8   temp_min                 1251 non-null   int64  \n",
      " 9   water_equivalent         1251 non-null   float64\n",
      " 10  snow_fall                1251 non-null   float64\n",
      " 11  snow_depth_6am           1251 non-null   float64\n",
      " 12  wind_speed_sum           1251 non-null   int64  \n",
      " 13  sunshine_percent         1251 non-null   int64  \n",
      " 14  west_wind_hours          1251 non-null   int64  \n",
      " 15  northwest_wind_hours     1251 non-null   int64  \n",
      " 16  prevailing_wind_E        1251 non-null   int64  \n",
      " 17  prevailing_wind_N        1251 non-null   int64  \n",
      " 18  prevailing_wind_NE       1251 non-null   int64  \n",
      " 19  prevailing_wind_NW       1251 non-null   int64  \n",
      " 20  prevailing_wind_S        1251 non-null   int64  \n",
      " 21  prevailing_wind_SE       1251 non-null   int64  \n",
      " 22  prevailing_wind_SW       1251 non-null   int64  \n",
      " 23  prevailing_wind_W        1251 non-null   int64  \n",
      " 24  next_day_avi_danger      1251 non-null   float64\n",
      "dtypes: float64(11), int64(14)\n",
      "memory usage: 254.1 KB\n"
     ]
    }
   ],
   "source": [
    "avi = avi.fillna(0)\n",
    "avi = avi[avi.avi_danger != 5]\n",
    "avi.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Splitting Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1251, 24)\n",
      "(1251,)\n"
     ]
    }
   ],
   "source": [
    "x = avi.iloc[:, 1:avi.shape[1]]\n",
    "y = avi.iloc[:, 0]\n",
    "\n",
    "print(x.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Standardizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#standardizer \n",
    "def standardize(X_train, X_test):\n",
    "    scaler = StandardScaler()\n",
    "    # Fitting and transforming training data\n",
    "    scaler.fit(X_train)\n",
    "    X_train = scaler.transform(X_train)\n",
    "    # Tranforming testing data based on traning fit (prevent data leakage)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    return X_train, X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=42)\n",
    "\n",
    "# Scaling\n",
    "x_train, x_test = standardize(x_train, x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       2.0\n",
      "1       1.0\n",
      "2       1.0\n",
      "3       3.0\n",
      "4       2.0\n",
      "       ... \n",
      "1248    1.0\n",
      "1249    3.0\n",
      "1250    3.0\n",
      "1251    3.0\n",
      "1252    2.0\n",
      "Name: avi_danger, Length: 1251, dtype: float64\n",
      "[[  1. 370.]\n",
      " [  2. 474.]\n",
      " [  3. 339.]\n",
      " [  4.  68.]]\n"
     ]
    }
   ],
   "source": [
    "print(y)\n",
    "\n",
    "(unique, counts) = np.unique(y, return_counts=True)\n",
    "frequencies = np.asarray((unique, counts)).T\n",
    "\n",
    "print(frequencies)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Descision Trees "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5143769968051118\n",
      "[0.56230032 0.41853035 0.56089744]\n"
     ]
    }
   ],
   "source": [
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "# Create the random grid\n",
    "random_grid = {'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "              }\n",
    "\n",
    "\n",
    "ds = DecisionTreeClassifier()\n",
    "ds_cv = RandomizedSearchCV(estimator=ds, param_distributions=random_grid, n_iter=100, scoring='f1_weighted')\n",
    "ds_cv.fit(x_train, y_train)\n",
    "y_pred_ds = ds_cv.predict(x_test)\n",
    "print(accuracy_score(y_test, y_pred_ds))\n",
    "print(cross_val_score(ds, x_train, y_train, cv=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[63 25  9  1]\n",
      " [26 68 25  2]\n",
      " [ 7 32 28  6]\n",
      " [ 3  5 11  2]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, y_pred_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.64      0.64      0.64        98\n",
      "         2.0       0.52      0.56      0.54       121\n",
      "         3.0       0.38      0.38      0.38        73\n",
      "         4.0       0.18      0.10      0.12        21\n",
      "\n",
      "    accuracy                           0.51       313\n",
      "   macro avg       0.43      0.42      0.42       313\n",
      "weighted avg       0.50      0.51      0.51       313\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(classification_report(y_test, y_pred_ds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6293929712460063\n",
      "[0.65814696 0.65495208 0.63141026]\n"
     ]
    }
   ],
   "source": [
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "\n",
    "\n",
    "rf = RandomForestClassifier(class_weight = \"balanced\")\n",
    "rf_cv = RandomizedSearchCV(estimator=rf, param_distributions=random_grid, n_iter=5, scoring='f1_weighted')\n",
    "rf_cv.fit(x_train, y_train)\n",
    "y_pred_rf = rf_cv.predict(x_test)\n",
    "print(accuracy_score(y_test, y_pred_rf))\n",
    "print(cross_val_score(rf, x_train, y_train, cv=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[73 19  6  0]\n",
      " [16 76 28  1]\n",
      " [ 3 24 46  0]\n",
      " [ 0  1 18  2]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, y_pred_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.79      0.74      0.77        98\n",
      "         2.0       0.63      0.63      0.63       121\n",
      "         3.0       0.47      0.63      0.54        73\n",
      "         4.0       0.67      0.10      0.17        21\n",
      "\n",
      "    accuracy                           0.63       313\n",
      "   macro avg       0.64      0.52      0.53       313\n",
      "weighted avg       0.65      0.63      0.62       313\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred_rf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6198083067092651\n",
      "[0.63578275 0.64217252 0.6474359 ]\n"
     ]
    }
   ],
   "source": [
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "\n",
    "et = ExtraTreesClassifier(class_weight = \"balanced\")\n",
    "et_cv = RandomizedSearchCV(estimator=et, param_distributions=random_grid, n_iter=5, scoring='f1_weighted')\n",
    "et_cv.fit(x_train, y_train)\n",
    "y_pred_et = et_cv.predict(x_test)\n",
    "print(accuracy_score(y_test, y_pred_et))\n",
    "print(cross_val_score(rf, x_train, y_train, cv=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[75 15  8  0]\n",
      " [20 68 31  2]\n",
      " [ 3 18 46  6]\n",
      " [ 1  1 14  5]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, y_pred_et))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.76      0.77      0.76        98\n",
      "         2.0       0.67      0.56      0.61       121\n",
      "         3.0       0.46      0.63      0.53        73\n",
      "         4.0       0.38      0.24      0.29        21\n",
      "\n",
      "    accuracy                           0.62       313\n",
      "   macro avg       0.57      0.55      0.55       313\n",
      "weighted avg       0.63      0.62      0.62       313\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred_et))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
