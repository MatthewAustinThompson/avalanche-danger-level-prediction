{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Danger Level Forecasting Preliminary Models\n",
    "\n",
    "Testing out some of the classification models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# sklearn \n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, ExtraTreesClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0_x</th>\n",
       "      <th>AVY_DANGER</th>\n",
       "      <th>AWND</th>\n",
       "      <th>SNOW</th>\n",
       "      <th>FIVE_DAY_SNOWFALL</th>\n",
       "      <th>TMAX_SWING</th>\n",
       "      <th>TMAX_SWING_FROM_AVE</th>\n",
       "      <th>WDF5</th>\n",
       "      <th>...</th>\n",
       "      <th>day_y</th>\n",
       "      <th>prevailing_wind_E</th>\n",
       "      <th>prevailing_wind_N</th>\n",
       "      <th>prevailing_wind_NE</th>\n",
       "      <th>prevailing_wind_NW</th>\n",
       "      <th>prevailing_wind_S</th>\n",
       "      <th>prevailing_wind_SE</th>\n",
       "      <th>prevailing_wind_SW</th>\n",
       "      <th>prevailing_wind_W</th>\n",
       "      <th>prevailing_wind_na</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.74</td>\n",
       "      <td>0.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>320.0</td>\n",
       "      <td>...</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.40</td>\n",
       "      <td>0.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>180.0</td>\n",
       "      <td>...</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.58</td>\n",
       "      <td>2.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>360.0</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>35.12</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>360.0</td>\n",
       "      <td>...</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>33.78</td>\n",
       "      <td>4.1</td>\n",
       "      <td>8.6</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>360.0</td>\n",
       "      <td>...</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Unnamed: 0.1  Unnamed: 0_x  AVY_DANGER   AWND  SNOW  \\\n",
       "0           0             0             0         2.0  10.74   0.2   \n",
       "1           1             1             1         1.0   9.40   0.1   \n",
       "2           2             2             2         1.0  20.58   2.2   \n",
       "3           3             3             3         3.0  35.12   2.0   \n",
       "4           4             4             4         2.0  33.78   4.1   \n",
       "\n",
       "   FIVE_DAY_SNOWFALL  TMAX_SWING  TMAX_SWING_FROM_AVE   WDF5  ...  day_y  \\\n",
       "0                NaN         NaN                  NaN  320.0  ...     18   \n",
       "1                NaN         3.0                  NaN  180.0  ...     19   \n",
       "2                NaN         0.0                  NaN  360.0  ...     20   \n",
       "3                NaN         3.0                  NaN  360.0  ...     21   \n",
       "4                8.6        -3.0                  NaN  360.0  ...     22   \n",
       "\n",
       "   prevailing_wind_E  prevailing_wind_N  prevailing_wind_NE  \\\n",
       "0                  0                  0                   0   \n",
       "1                  0                  0                   0   \n",
       "2                  0                  1                   0   \n",
       "3                  0                  1                   0   \n",
       "4                  0                  1                   0   \n",
       "\n",
       "   prevailing_wind_NW  prevailing_wind_S  prevailing_wind_SE  \\\n",
       "0                   1                  0                   0   \n",
       "1                   1                  0                   0   \n",
       "2                   0                  0                   0   \n",
       "3                   0                  0                   0   \n",
       "4                   0                  0                   0   \n",
       "\n",
       "   prevailing_wind_SW  prevailing_wind_W  prevailing_wind_na  \n",
       "0                   0                  0                   0  \n",
       "1                   0                  0                   0  \n",
       "2                   0                  0                   0  \n",
       "3                   0                  0                   0  \n",
       "4                   0                  0                   0  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avi = pd.read_csv('snowweatheModel.csv')\n",
    "avi.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### filter data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "avi = avi.drop(['Unnamed: 0', 'Unnamed: 0.1', 'Unnamed: 0_x', 'Unnamed: 0_y'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1254 entries, 0 to 1356\n",
      "Data columns (total 31 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   AVY_DANGER            1254 non-null   float64\n",
      " 1   AWND                  1225 non-null   float64\n",
      " 2   SNOW                  1253 non-null   float64\n",
      " 3   FIVE_DAY_SNOWFALL     1244 non-null   float64\n",
      " 4   TMAX_SWING            1251 non-null   float64\n",
      " 5   TMAX_SWING_FROM_AVE   1242 non-null   float64\n",
      " 6   WDF5                  1225 non-null   float64\n",
      " 7   year_x                1254 non-null   float64\n",
      " 8   month_x               1254 non-null   float64\n",
      " 9   day_x                 1254 non-null   float64\n",
      " 10  temp_max              1254 non-null   int64  \n",
      " 11  temp_min              1254 non-null   int64  \n",
      " 12  water_equivalent      1254 non-null   float64\n",
      " 13  snow_fall             1254 non-null   float64\n",
      " 14  snow_depth_6am        1254 non-null   float64\n",
      " 15  wind_speed_sum        1254 non-null   int64  \n",
      " 16  sunshine_percent      1254 non-null   int64  \n",
      " 17  west_wind_hours       1254 non-null   int64  \n",
      " 18  northwest_wind_hours  1254 non-null   int64  \n",
      " 19  year_y                1254 non-null   int64  \n",
      " 20  month_y               1254 non-null   int64  \n",
      " 21  day_y                 1254 non-null   int64  \n",
      " 22  prevailing_wind_E     1254 non-null   int64  \n",
      " 23  prevailing_wind_N     1254 non-null   int64  \n",
      " 24  prevailing_wind_NE    1254 non-null   int64  \n",
      " 25  prevailing_wind_NW    1254 non-null   int64  \n",
      " 26  prevailing_wind_S     1254 non-null   int64  \n",
      " 27  prevailing_wind_SE    1254 non-null   int64  \n",
      " 28  prevailing_wind_SW    1254 non-null   int64  \n",
      " 29  prevailing_wind_W     1254 non-null   int64  \n",
      " 30  prevailing_wind_na    1254 non-null   int64  \n",
      "dtypes: float64(13), int64(18)\n",
      "memory usage: 313.5 KB\n"
     ]
    }
   ],
   "source": [
    "avi = avi[avi['AVY_DANGER'].notnull()]\n",
    "avi.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fill Remaing NA's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1252 entries, 0 to 1356\n",
      "Data columns (total 31 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   AVY_DANGER            1252 non-null   float64\n",
      " 1   AWND                  1252 non-null   float64\n",
      " 2   SNOW                  1252 non-null   float64\n",
      " 3   FIVE_DAY_SNOWFALL     1252 non-null   float64\n",
      " 4   TMAX_SWING            1252 non-null   float64\n",
      " 5   TMAX_SWING_FROM_AVE   1252 non-null   float64\n",
      " 6   WDF5                  1252 non-null   float64\n",
      " 7   year_x                1252 non-null   float64\n",
      " 8   month_x               1252 non-null   float64\n",
      " 9   day_x                 1252 non-null   float64\n",
      " 10  temp_max              1252 non-null   int64  \n",
      " 11  temp_min              1252 non-null   int64  \n",
      " 12  water_equivalent      1252 non-null   float64\n",
      " 13  snow_fall             1252 non-null   float64\n",
      " 14  snow_depth_6am        1252 non-null   float64\n",
      " 15  wind_speed_sum        1252 non-null   int64  \n",
      " 16  sunshine_percent      1252 non-null   int64  \n",
      " 17  west_wind_hours       1252 non-null   int64  \n",
      " 18  northwest_wind_hours  1252 non-null   int64  \n",
      " 19  year_y                1252 non-null   int64  \n",
      " 20  month_y               1252 non-null   int64  \n",
      " 21  day_y                 1252 non-null   int64  \n",
      " 22  prevailing_wind_E     1252 non-null   int64  \n",
      " 23  prevailing_wind_N     1252 non-null   int64  \n",
      " 24  prevailing_wind_NE    1252 non-null   int64  \n",
      " 25  prevailing_wind_NW    1252 non-null   int64  \n",
      " 26  prevailing_wind_S     1252 non-null   int64  \n",
      " 27  prevailing_wind_SE    1252 non-null   int64  \n",
      " 28  prevailing_wind_SW    1252 non-null   int64  \n",
      " 29  prevailing_wind_W     1252 non-null   int64  \n",
      " 30  prevailing_wind_na    1252 non-null   int64  \n",
      "dtypes: float64(13), int64(18)\n",
      "memory usage: 313.0 KB\n"
     ]
    }
   ],
   "source": [
    "avi = avi.fillna(0)\n",
    "avi = avi[avi.AVY_DANGER != 5]\n",
    "avi.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Splitting Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1252, 30)\n",
      "(1252,)\n"
     ]
    }
   ],
   "source": [
    "x = avi.iloc[:, 1:avi.shape[1]]\n",
    "y = avi.iloc[:, 0]\n",
    "\n",
    "print(x.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Standardizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#standardizer \n",
    "def standardize(X_train, X_test):\n",
    "    scaler = StandardScaler()\n",
    "    # Fitting and transforming training data\n",
    "    scaler.fit(X_train)\n",
    "    X_train = scaler.transform(X_train)\n",
    "    # Tranforming testing data based on traning fit (prevent data leakage)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    return X_train, X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'StandardScaler' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-77-0971d61177e5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Scaling\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstandardize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-76-60f435415e88>\u001b[0m in \u001b[0;36mstandardize\u001b[0;34m(X_train, X_test)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#standardizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mstandardize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mscaler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;31m# Fitting and transforming training data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'StandardScaler' is not defined"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=42)\n",
    "\n",
    "# Scaling\n",
    "x_train, x_test = standardize(x_train, x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       2.0\n",
      "1       1.0\n",
      "2       1.0\n",
      "3       3.0\n",
      "4       2.0\n",
      "       ... \n",
      "1352    3.0\n",
      "1353    3.0\n",
      "1354    3.0\n",
      "1355    2.0\n",
      "1356    1.0\n",
      "Name: AVY_DANGER, Length: 1252, dtype: float64\n",
      "[[  1. 371.]\n",
      " [  2. 474.]\n",
      " [  3. 339.]\n",
      " [  4.  68.]]\n"
     ]
    }
   ],
   "source": [
    "print(y)\n",
    "\n",
    "(unique, counts) = np.unique(y, return_counts=True)\n",
    "frequencies = np.asarray((unique, counts)).T\n",
    "\n",
    "print(frequencies)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Descision Trees "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5559105431309904\n",
      "[0.53354633 0.53354633 0.50798722]\n"
     ]
    }
   ],
   "source": [
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "# Create the random grid\n",
    "random_grid = {'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "              }\n",
    "\n",
    "\n",
    "ds = DecisionTreeClassifier()\n",
    "ds_cv = RandomizedSearchCV(estimator=ds, param_distributions=random_grid, n_iter=100, scoring='f1_weighted')\n",
    "ds_cv.fit(x_train, y_train)\n",
    "y_pred_ds = ds_cv.predict(x_test)\n",
    "print(accuracy_score(y_test, y_pred_ds))\n",
    "print(cross_val_score(ds, x_train, y_train, cv=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[64 13 19  1]\n",
      " [18 67 34  1]\n",
      " [13 18 39  5]\n",
      " [ 2  4 11  4]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, y_pred_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.66      0.66      0.66        97\n",
      "         2.0       0.66      0.56      0.60       120\n",
      "         3.0       0.38      0.52      0.44        75\n",
      "         4.0       0.36      0.19      0.25        21\n",
      "\n",
      "    accuracy                           0.56       313\n",
      "   macro avg       0.51      0.48      0.49       313\n",
      "weighted avg       0.57      0.56      0.56       313\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(classification_report(y_test, y_pred_ds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6325878594249201\n",
      "[0.61341853 0.61022364 0.60383387]\n"
     ]
    }
   ],
   "source": [
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "\n",
    "\n",
    "rf = RandomForestClassifier(class_weight = \"balanced\")\n",
    "rf_cv = RandomizedSearchCV(estimator=rf, param_distributions=random_grid, n_iter=5, scoring='f1_weighted')\n",
    "rf_cv.fit(x_train, y_train)\n",
    "y_pred_rf = rf_cv.predict(x_test)\n",
    "print(accuracy_score(y_test, y_pred_rf))\n",
    "print(cross_val_score(rf, x_train, y_train, cv=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[76 12  9  0]\n",
      " [13 74 32  1]\n",
      " [ 4 20 41 10]\n",
      " [ 0  1 13  7]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, y_pred_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.83      0.74      0.78        87\n",
      "         2.0       0.67      0.75      0.71       115\n",
      "         3.0       0.56      0.57      0.56        86\n",
      "         4.0       0.50      0.33      0.40        15\n",
      "\n",
      "    accuracy                           0.67       303\n",
      "   macro avg       0.64      0.60      0.61       303\n",
      "weighted avg       0.68      0.67      0.67       303\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred_rf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6336633663366337\n",
      "[0.62706271 0.62046205 0.64686469]\n"
     ]
    }
   ],
   "source": [
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "\n",
    "et = ExtraTreesClassifier(class_weight = \"balanced\")\n",
    "et_cv = RandomizedSearchCV(estimator=et, param_distributions=random_grid, n_iter=5, scoring='f1_weighted')\n",
    "et_cv.fit(x_train, y_train)\n",
    "y_pred_et = et_cv.predict(x_test)\n",
    "print(accuracy_score(y_test, y_pred_et))\n",
    "print(cross_val_score(rf, x_train, y_train, cv=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[54 25  8  0]\n",
      " [11 89 15  0]\n",
      " [ 6 32 48  0]\n",
      " [ 0  1 13  1]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, y_pred_et))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.76      0.62      0.68        87\n",
      "         2.0       0.61      0.77      0.68       115\n",
      "         3.0       0.57      0.56      0.56        86\n",
      "         4.0       1.00      0.07      0.12        15\n",
      "\n",
      "    accuracy                           0.63       303\n",
      "   macro avg       0.73      0.50      0.51       303\n",
      "weighted avg       0.66      0.63      0.62       303\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred_et))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
