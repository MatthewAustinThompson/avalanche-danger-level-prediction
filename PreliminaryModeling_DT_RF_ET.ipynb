{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Danger Level Forecasting Preliminary Models\n",
    "\n",
    "Testing out some of the classification models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# sklearn \n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, ExtraTreesClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>avi_danger</th>\n",
       "      <th>avg_wind</th>\n",
       "      <th>temp_max_swing</th>\n",
       "      <th>temp_max_swing_from_avg</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>temp_max</th>\n",
       "      <th>temp_min</th>\n",
       "      <th>...</th>\n",
       "      <th>northwest_wind_hours</th>\n",
       "      <th>prevailing_wind_E</th>\n",
       "      <th>prevailing_wind_N</th>\n",
       "      <th>prevailing_wind_NE</th>\n",
       "      <th>prevailing_wind_NW</th>\n",
       "      <th>prevailing_wind_S</th>\n",
       "      <th>prevailing_wind_SE</th>\n",
       "      <th>prevailing_wind_SW</th>\n",
       "      <th>prevailing_wind_W</th>\n",
       "      <th>next_day_avi_danger</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.74</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.40</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.58</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>35.12</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>18</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>33.78</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>15</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  avi_danger  avg_wind  temp_max_swing  temp_max_swing_from_avg  \\\n",
       "0           0         2.0     10.74             0.0                      0.0   \n",
       "1           1         1.0      9.40             3.0                      0.0   \n",
       "2           2         1.0     20.58             0.0                      0.0   \n",
       "3           3         3.0     35.12             3.0                      0.0   \n",
       "4           4         2.0     33.78            -3.0                      0.0   \n",
       "\n",
       "     year  month   day  temp_max  temp_min  ...  northwest_wind_hours  \\\n",
       "0  2010.0   12.0  18.0        12         4  ...                    12   \n",
       "1  2010.0   12.0  19.0        15         3  ...                    12   \n",
       "2  2010.0   12.0  20.0        15         5  ...                     0   \n",
       "3  2010.0   12.0  21.0        18        10  ...                     0   \n",
       "4  2010.0   12.0  22.0        15         7  ...                     1   \n",
       "\n",
       "   prevailing_wind_E  prevailing_wind_N  prevailing_wind_NE  \\\n",
       "0                  0                  0                   0   \n",
       "1                  0                  0                   0   \n",
       "2                  0                  1                   0   \n",
       "3                  0                  1                   0   \n",
       "4                  0                  1                   0   \n",
       "\n",
       "   prevailing_wind_NW  prevailing_wind_S  prevailing_wind_SE  \\\n",
       "0                   1                  0                   0   \n",
       "1                   1                  0                   0   \n",
       "2                   0                  0                   0   \n",
       "3                   0                  0                   0   \n",
       "4                   0                  0                   0   \n",
       "\n",
       "   prevailing_wind_SW  prevailing_wind_W  next_day_avi_danger  \n",
       "0                   0                  0                  1.0  \n",
       "1                   0                  0                  1.0  \n",
       "2                   0                  0                  3.0  \n",
       "3                   0                  0                  2.0  \n",
       "4                   0                  0                  3.0  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avi = pd.read_csv('SnowWeatherClean.csv')\n",
    "avi.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### filter data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "avi = avi.drop(['Unnamed: 0'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1253 entries, 0 to 1252\n",
      "Data columns (total 25 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   avi_danger               1253 non-null   float64\n",
      " 1   avg_wind                 1253 non-null   float64\n",
      " 2   temp_max_swing           1253 non-null   float64\n",
      " 3   temp_max_swing_from_avg  1253 non-null   float64\n",
      " 4   year                     1253 non-null   float64\n",
      " 5   month                    1253 non-null   float64\n",
      " 6   day                      1253 non-null   float64\n",
      " 7   temp_max                 1253 non-null   int64  \n",
      " 8   temp_min                 1253 non-null   int64  \n",
      " 9   water_equivalent         1253 non-null   float64\n",
      " 10  snow_fall                1253 non-null   float64\n",
      " 11  snow_depth_6am           1253 non-null   float64\n",
      " 12  wind_speed_sum           1253 non-null   int64  \n",
      " 13  sunshine_percent         1253 non-null   int64  \n",
      " 14  west_wind_hours          1253 non-null   int64  \n",
      " 15  northwest_wind_hours     1253 non-null   int64  \n",
      " 16  prevailing_wind_E        1253 non-null   int64  \n",
      " 17  prevailing_wind_N        1253 non-null   int64  \n",
      " 18  prevailing_wind_NE       1253 non-null   int64  \n",
      " 19  prevailing_wind_NW       1253 non-null   int64  \n",
      " 20  prevailing_wind_S        1253 non-null   int64  \n",
      " 21  prevailing_wind_SE       1253 non-null   int64  \n",
      " 22  prevailing_wind_SW       1253 non-null   int64  \n",
      " 23  prevailing_wind_W        1253 non-null   int64  \n",
      " 24  next_day_avi_danger      1253 non-null   float64\n",
      "dtypes: float64(11), int64(14)\n",
      "memory usage: 254.5 KB\n"
     ]
    }
   ],
   "source": [
    "avi = avi[avi['avi_danger'].notnull()]\n",
    "avi.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fill Remaing NA's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1249 entries, 0 to 1252\n",
      "Data columns (total 25 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   avi_danger               1249 non-null   float64\n",
      " 1   avg_wind                 1249 non-null   float64\n",
      " 2   temp_max_swing           1249 non-null   float64\n",
      " 3   temp_max_swing_from_avg  1249 non-null   float64\n",
      " 4   year                     1249 non-null   float64\n",
      " 5   month                    1249 non-null   float64\n",
      " 6   day                      1249 non-null   float64\n",
      " 7   temp_max                 1249 non-null   int64  \n",
      " 8   temp_min                 1249 non-null   int64  \n",
      " 9   water_equivalent         1249 non-null   float64\n",
      " 10  snow_fall                1249 non-null   float64\n",
      " 11  snow_depth_6am           1249 non-null   float64\n",
      " 12  wind_speed_sum           1249 non-null   int64  \n",
      " 13  sunshine_percent         1249 non-null   int64  \n",
      " 14  west_wind_hours          1249 non-null   int64  \n",
      " 15  northwest_wind_hours     1249 non-null   int64  \n",
      " 16  prevailing_wind_E        1249 non-null   int64  \n",
      " 17  prevailing_wind_N        1249 non-null   int64  \n",
      " 18  prevailing_wind_NE       1249 non-null   int64  \n",
      " 19  prevailing_wind_NW       1249 non-null   int64  \n",
      " 20  prevailing_wind_S        1249 non-null   int64  \n",
      " 21  prevailing_wind_SE       1249 non-null   int64  \n",
      " 22  prevailing_wind_SW       1249 non-null   int64  \n",
      " 23  prevailing_wind_W        1249 non-null   int64  \n",
      " 24  next_day_avi_danger      1249 non-null   float64\n",
      "dtypes: float64(11), int64(14)\n",
      "memory usage: 253.7 KB\n"
     ]
    }
   ],
   "source": [
    "avi = avi.fillna(0)\n",
    "avi = avi[avi.avi_danger != 5]\n",
    "avi = avi[avi.next_day_avi_danger != 5]\n",
    "avi.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Splitting Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1249, 23)\n",
      "(1249,)\n"
     ]
    }
   ],
   "source": [
    "x = avi.iloc[:, 0:avi.shape[1]-2]\n",
    "y = avi.iloc[:, avi.shape[1]-1]\n",
    "\n",
    "print(x.shape)\n",
    "print(y.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Standardizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#standardizer \n",
    "def standardize(X_train, X_test):\n",
    "    scaler = StandardScaler()\n",
    "    # Fitting and transforming training data\n",
    "    scaler.fit(X_train)\n",
    "    X_train = scaler.transform(X_train)\n",
    "    # Tranforming testing data based on traning fit (prevent data leakage)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    return X_train, X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=42)\n",
    "\n",
    "# Scaling\n",
    "x_train, x_test = standardize(x_train, x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       1.0\n",
      "1       1.0\n",
      "2       3.0\n",
      "3       2.0\n",
      "4       3.0\n",
      "       ... \n",
      "1248    3.0\n",
      "1249    3.0\n",
      "1250    3.0\n",
      "1251    2.0\n",
      "1252    1.0\n",
      "Name: next_day_avi_danger, Length: 1249, dtype: float64\n",
      "[[  1. 371.]\n",
      " [  2. 473.]\n",
      " [  3. 337.]\n",
      " [  4.  68.]]\n"
     ]
    }
   ],
   "source": [
    "print(y)\n",
    "\n",
    "(unique, counts) = np.unique(y, return_counts=True)\n",
    "frequencies = np.asarray((unique, counts)).T\n",
    "\n",
    "print(frequencies)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Descision Trees "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5591054313099042\n",
      "[0.51282051 0.49358974 0.49679487]\n"
     ]
    }
   ],
   "source": [
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "# Create the random grid\n",
    "random_grid = {'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "              }\n",
    "\n",
    "\n",
    "ds = DecisionTreeClassifier()\n",
    "ds_cv = RandomizedSearchCV(estimator=ds, param_distributions=random_grid, n_iter=100, scoring='f1_weighted')\n",
    "ds_cv.fit(x_train, y_train)\n",
    "y_pred_ds = ds_cv.predict(x_test)\n",
    "print(accuracy_score(y_test, y_pred_ds))\n",
    "print(cross_val_score(ds, x_train, y_train, cv=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[72 13 10  0]\n",
      " [13 65 29  1]\n",
      " [ 9 38 30 11]\n",
      " [ 5  6  3  8]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, y_pred_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.73      0.76      0.74        95\n",
      "         2.0       0.53      0.60      0.57       108\n",
      "         3.0       0.42      0.34      0.37        88\n",
      "         4.0       0.40      0.36      0.38        22\n",
      "\n",
      "    accuracy                           0.56       313\n",
      "   macro avg       0.52      0.52      0.52       313\n",
      "weighted avg       0.55      0.56      0.55       313\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(classification_report(y_test, y_pred_ds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6070287539936102\n",
      "[0.61217949 0.63141026 0.59935897]\n"
     ]
    }
   ],
   "source": [
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "\n",
    "\n",
    "rf = RandomForestClassifier(class_weight = \"balanced\")\n",
    "rf_cv = RandomizedSearchCV(estimator=rf, param_distributions=random_grid, n_iter=5, scoring='f1_weighted')\n",
    "rf_cv.fit(x_train, y_train)\n",
    "y_pred_rf = rf_cv.predict(x_test)\n",
    "print(accuracy_score(y_test, y_pred_rf))\n",
    "print(cross_val_score(rf, x_train, y_train, cv=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[75 15  5  0]\n",
      " [12 72 22  2]\n",
      " [10 38 40  0]\n",
      " [ 2  7 10  3]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, y_pred_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.76      0.79      0.77        95\n",
      "         2.0       0.55      0.67      0.60       108\n",
      "         3.0       0.52      0.45      0.48        88\n",
      "         4.0       0.60      0.14      0.22        22\n",
      "\n",
      "    accuracy                           0.61       313\n",
      "   macro avg       0.61      0.51      0.52       313\n",
      "weighted avg       0.61      0.61      0.59       313\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred_rf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.610223642172524\n",
      "[0.61217949 0.60576923 0.59615385]\n"
     ]
    }
   ],
   "source": [
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "\n",
    "et = ExtraTreesClassifier(class_weight = \"balanced\")\n",
    "et_cv = RandomizedSearchCV(estimator=et, param_distributions=random_grid, n_iter=5, scoring='f1_weighted')\n",
    "et_cv.fit(x_train, y_train)\n",
    "y_pred_et = et_cv.predict(x_test)\n",
    "print(accuracy_score(y_test, y_pred_et))\n",
    "print(cross_val_score(rf, x_train, y_train, cv=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[77 11  7  0]\n",
      " [13 67 26  2]\n",
      " [12 33 42  1]\n",
      " [ 3  6  8  5]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, y_pred_et))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.73      0.81      0.77        95\n",
      "         2.0       0.57      0.62      0.60       108\n",
      "         3.0       0.51      0.48      0.49        88\n",
      "         4.0       0.62      0.23      0.33        22\n",
      "\n",
      "    accuracy                           0.61       313\n",
      "   macro avg       0.61      0.53      0.55       313\n",
      "weighted avg       0.61      0.61      0.60       313\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred_et))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
